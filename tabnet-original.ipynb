{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-11-30T08:06:37.438688Z",
     "iopub.status.busy": "2020-11-30T08:06:37.437734Z",
     "iopub.status.idle": "2020-11-30T08:06:37.450350Z",
     "shell.execute_reply": "2020-11-30T08:06:37.449746Z"
    },
    "papermill": {
     "duration": 0.038055,
     "end_time": "2020-11-30T08:06:37.450455",
     "exception": false,
     "start_time": "2020-11-30T08:06:37.412400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/lish-moa/train_targets_scored.csv\n",
      "/kaggle/input/lish-moa/train_drug.csv\n",
      "/kaggle/input/lish-moa/train_targets_nonscored.csv\n",
      "/kaggle/input/lish-moa/train_features.csv\n",
      "/kaggle/input/lish-moa/sample_submission.csv\n",
      "/kaggle/input/lish-moa/test_features.csv\n",
      "/kaggle/input/rank-gauss/rankGaussTrafo.py\n",
      "/kaggle/input/rank-gauss/gauss_rank_scaler.py\n",
      "/kaggle/input/rank-gauss/rgn.py\n",
      "/kaggle/input/pytorchtabnet/pytorch_tabnet-2.0.1-py3-none-any.whl\n",
      "/kaggle/input/pytorchtabnet/pytorch_tabnet-1.2.0-py3-none-any.whl\n",
      "/kaggle/input/pytorchtabnet/pytorch_tabnet-2.0.0-py3-none-any.whl\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/setup.py\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/.travis.yml\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/setup.cfg\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/.gitignore\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/LICENSE\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/README.md\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/iterstrat/__init__.py\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/iterstrat/ml_stratifiers.py\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/tests/__init__.py\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/tests/test_ml_stratifiers.py\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-11-30T08:06:37.494740Z",
     "iopub.status.busy": "2020-11-30T08:06:37.493916Z",
     "iopub.status.idle": "2020-11-30T08:07:16.063195Z",
     "shell.execute_reply": "2020-11-30T08:07:16.061905Z"
    },
    "papermill": {
     "duration": 38.593977,
     "end_time": "2020-11-30T08:07:16.063376",
     "exception": false,
     "start_time": "2020-11-30T08:06:37.469399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /kaggle/input/pytorchtabnet/pytorch_tabnet-2.0.0-py3-none-any.whl\r\n",
      "Processing /kaggle/input/pytorchtabnet/pytorch_tabnet-2.0.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: scikit_learn>0.21 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (0.23.2)\r\n",
      "Requirement already satisfied: tqdm<5.0,>=4.36 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (4.45.0)\r\n",
      "Requirement already satisfied: torch<2.0,>=1.2 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.6.0)\r\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.18.5)\r\n",
      "Requirement already satisfied: scipy>1.4 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.4.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit_learn>0.21->pytorch-tabnet) (2.1.0)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit_learn>0.21->pytorch-tabnet) (0.14.1)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch<2.0,>=1.2->pytorch-tabnet) (0.18.2)\r\n",
      "Installing collected packages: pytorch-tabnet\r\n",
      "Successfully installed pytorch-tabnet-2.0.0\r\n",
      "Processing /kaggle/input/iterative-stratification/iterative-stratification-master\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from iterative-stratification==0.1.6) (1.18.5)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from iterative-stratification==0.1.6) (1.4.1)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from iterative-stratification==0.1.6) (0.23.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->iterative-stratification==0.1.6) (2.1.0)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->iterative-stratification==0.1.6) (0.14.1)\r\n",
      "Building wheels for collected packages: iterative-stratification\r\n",
      "  Building wheel for iterative-stratification (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for iterative-stratification: filename=iterative_stratification-0.1.6-py3-none-any.whl size=8401 sha256=7c876c29cae1c314201b5e7fc28bca9567ea80cfc788be2b8a055c89f5a16f11\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/b8/47/3f/eb4af42d124f37d23d6f13a4c8bbc32c1d70140e6e1cecb4aa\r\n",
      "Successfully built iterative-stratification\r\n",
      "Installing collected packages: iterative-stratification\r\n",
      "Successfully installed iterative-stratification-0.1.6\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-index --find-links /kaggle/input/pytorchtabnet/pytorch_tabnet-2.0.0-py3-none-any.whl pytorch-tabnet\n",
    "# Iterative Stratification\n",
    "!pip install /kaggle/input/iterative-stratification/iterative-stratification-master/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T08:07:16.144306Z",
     "iopub.status.busy": "2020-11-30T08:07:16.143377Z",
     "iopub.status.idle": "2020-11-30T08:07:18.821740Z",
     "shell.execute_reply": "2020-11-30T08:07:18.820621Z"
    },
    "papermill": {
     "duration": 2.72255,
     "end_time": "2020-11-30T08:07:18.821883",
     "exception": false,
     "start_time": "2020-11-30T08:07:16.099333",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### General ###\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import tqdm\n",
    "import pickle\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sys.path.append(\"../input/rank-gauss\")\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = '1'\n",
    "\n",
    "### Data Wrangling ###\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from gauss_rank_scaler import GaussRankScaler\n",
    "\n",
    "### Data Visualization ###\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "\n",
    "### Machine Learning ###\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "### Deep Learning ###\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "# Tabnet \n",
    "from pytorch_tabnet.metrics import Metric\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "### Make prettier the prints ###\n",
    "from colorama import Fore\n",
    "c_ = Fore.CYAN\n",
    "m_ = Fore.MAGENTA\n",
    "r_ = Fore.RED\n",
    "b_ = Fore.BLUE\n",
    "y_ = Fore.YELLOW\n",
    "g_ = Fore.GREEN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T08:07:18.877647Z",
     "iopub.status.busy": "2020-11-30T08:07:18.876894Z",
     "iopub.status.idle": "2020-11-30T08:07:19.226301Z",
     "shell.execute_reply": "2020-11-30T08:07:19.225758Z"
    },
    "papermill": {
     "duration": 0.381315,
     "end_time": "2020-11-30T08:07:19.226420",
     "exception": false,
     "start_time": "2020-11-30T08:07:18.845105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 5\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T08:07:19.279361Z",
     "iopub.status.busy": "2020-11-30T08:07:19.278640Z",
     "iopub.status.idle": "2020-11-30T08:07:19.282314Z",
     "shell.execute_reply": "2020-11-30T08:07:19.282768Z"
    },
    "papermill": {
     "duration": 0.032358,
     "end_time": "2020-11-30T08:07:19.282895",
     "exception": false,
     "start_time": "2020-11-30T08:07:19.250537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "data_path = \"../input/lish-moa/\"\n",
    "no_ctl = True\n",
    "scale = \"rankgauss\"\n",
    "variance_threshould = 0.7\n",
    "decompo = \"PCA\"\n",
    "ncompo_genes = 80\n",
    "ncompo_cells = 10\n",
    "encoding = \"dummy\"\n",
    "NB_SPLITS = 7 # 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T08:07:19.336893Z",
     "iopub.status.busy": "2020-11-30T08:07:19.335850Z",
     "iopub.status.idle": "2020-11-30T08:07:24.679984Z",
     "shell.execute_reply": "2020-11-30T08:07:24.678875Z"
    },
    "papermill": {
     "duration": 5.373246,
     "end_time": "2020-11-30T08:07:24.680105",
     "exception": false,
     "start_time": "2020-11-30T08:07:19.306859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(data_path + \"train_features.csv\")\n",
    "#train.drop(columns = [\"sig_id\"], inplace = True)\n",
    "\n",
    "targets = pd.read_csv(data_path + \"train_targets_scored.csv\")\n",
    "#train_targets_scored.drop(columns = [\"sig_id\"], inplace = True)\n",
    "\n",
    "#train_targets_nonscored = pd.read_csv(data_path + \"train_targets_nonscored.csv\")\n",
    "\n",
    "test = pd.read_csv(data_path + \"test_features.csv\")\n",
    "#test.drop(columns = [\"sig_id\"], inplace = True)\n",
    "\n",
    "submission = pd.read_csv(data_path + \"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T08:07:24.740901Z",
     "iopub.status.busy": "2020-11-30T08:07:24.739973Z",
     "iopub.status.idle": "2020-11-30T08:07:24.836267Z",
     "shell.execute_reply": "2020-11-30T08:07:24.836836Z"
    },
    "papermill": {
     "duration": 0.133114,
     "end_time": "2020-11-30T08:07:24.836968",
     "exception": false,
     "start_time": "2020-11-30T08:07:24.703854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m not_ctl\n"
     ]
    }
   ],
   "source": [
    "if no_ctl:\n",
    "    # cp_type == ctl_vehicle\n",
    "    print(b_, \"not_ctl\")\n",
    "    train = train[train[\"cp_type\"] != \"ctl_vehicle\"]\n",
    "    test = test[test[\"cp_type\"] != \"ctl_vehicle\"]\n",
    "    targets = targets.iloc[train.index]\n",
    "    train.reset_index(drop = True, inplace = True)\n",
    "    test.reset_index(drop = True, inplace = True)\n",
    "    targets.reset_index(drop = True, inplace = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T08:07:24.897293Z",
     "iopub.status.busy": "2020-11-30T08:07:24.896502Z",
     "iopub.status.idle": "2020-11-30T08:07:24.899592Z",
     "shell.execute_reply": "2020-11-30T08:07:24.900079Z"
    },
    "papermill": {
     "duration": 0.038778,
     "end_time": "2020-11-30T08:07:24.900229",
     "exception": false,
     "start_time": "2020-11-30T08:07:24.861451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def distributions(num, graphs, items, features, gorc):\n",
    "    \"\"\"\n",
    "    Plot the distributions of gene expression or cell viability data\n",
    "    \"\"\"\n",
    "    for i in range(0, num - 1, 7):\n",
    "        if i >= 3:\n",
    "            break\n",
    "        idxs = list(np.array([0, 1, 2, 3, 4, 5, 6]) + i)\n",
    "    \n",
    "        fig, axs = plt.subplots(1, 7, sharey = True)\n",
    "        for k, item in enumerate(idxs):\n",
    "            if item >= items:\n",
    "                break\n",
    "            graph = sns.distplot(train[features].values[:, item], ax = axs[k])\n",
    "            graph.set_title(f\"{gorc}-{item}\")\n",
    "            graphs.append(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T08:07:24.955279Z",
     "iopub.status.busy": "2020-11-30T08:07:24.954616Z",
     "iopub.status.idle": "2020-11-30T08:07:24.958662Z",
     "shell.execute_reply": "2020-11-30T08:07:24.958186Z"
    },
    "papermill": {
     "duration": 0.033599,
     "end_time": "2020-11-30T08:07:24.958749",
     "exception": false,
     "start_time": "2020-11-30T08:07:24.925150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "GENES = [col for col in train.columns if col.startswith(\"g-\")]\n",
    "CELLS = [col for col in train.columns if col.startswith(\"c-\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T08:07:25.018301Z",
     "iopub.status.busy": "2020-11-30T08:07:25.017188Z",
     "iopub.status.idle": "2020-11-30T08:07:25.411329Z",
     "shell.execute_reply": "2020-11-30T08:07:25.411875Z"
    },
    "papermill": {
     "duration": 0.429082,
     "end_time": "2020-11-30T08:07:25.412009",
     "exception": false,
     "start_time": "2020-11-30T08:07:24.982927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_all.shape (25572, 876)\n",
      "872\n",
      "mask.shape (872,)\n"
     ]
    }
   ],
   "source": [
    "#rank gauss\n",
    "data_all = pd.concat([train, test], ignore_index = True)\n",
    "print('data_all.shape',data_all.shape)\n",
    "cols_numeric = [feat for feat in list(data_all.columns) if feat not in [\"sig_id\", \"cp_type\", \"cp_time\", \"cp_dose\"]]\n",
    "\n",
    "print(len(cols_numeric))\n",
    "\n",
    "mask = (data_all[cols_numeric].var() >= variance_threshould).values\n",
    "\n",
    "print('mask.shape',mask.shape)\n",
    "tmp = data_all[cols_numeric].loc[:, mask]\n",
    "data_all = pd.concat([data_all[[\"sig_id\", \"cp_type\", \"cp_time\", \"cp_dose\"]], tmp], axis = 1)\n",
    "cols_numeric = [feat for feat in list(data_all.columns) if feat not in [\"sig_id\", \"cp_type\", \"cp_time\", \"cp_dose\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T08:07:25.475555Z",
     "iopub.status.busy": "2020-11-30T08:07:25.474429Z",
     "iopub.status.idle": "2020-11-30T08:07:41.275886Z",
     "shell.execute_reply": "2020-11-30T08:07:41.277093Z"
    },
    "papermill": {
     "duration": 15.840289,
     "end_time": "2020-11-30T08:07:41.277307",
     "exception": false,
     "start_time": "2020-11-30T08:07:25.437018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m Rank Gauss\n"
     ]
    }
   ],
   "source": [
    "def scale_minmax(col):\n",
    "    return (col - col.min()) / (col.max() - col.min())\n",
    "\n",
    "def scale_norm(col):\n",
    "    return (col - col.mean()) / col.std()\n",
    "\n",
    "if scale == \"boxcox\":\n",
    "    print(b_, \"boxcox\")\n",
    "    data_all[cols_numeric] = data_all[cols_numeric].apply(scale_minmax, axis = 0)\n",
    "    trans = []\n",
    "    for feat in cols_numeric:\n",
    "        trans_var, lambda_var = stats.boxcox(data_all[feat].dropna() + 1)\n",
    "        trans.append(scale_minmax(trans_var))\n",
    "    data_all[cols_numeric] = np.asarray(trans).T\n",
    "    \n",
    "elif scale == \"norm\":\n",
    "    print(b_, \"norm\")\n",
    "    data_all[cols_numeric] = data_all[cols_numeric].apply(scale_norm, axis = 0)\n",
    "    \n",
    "elif scale == \"minmax\":\n",
    "    print(b_, \"minmax\")\n",
    "    data_all[cols_numeric] = data_all[cols_numeric].apply(scale_minmax, axis = 0)\n",
    "elif scale == \"rankgauss\":\n",
    "    ### Rank Gauss ###\n",
    "    print(b_, \"Rank Gauss\")\n",
    "    scaler = GaussRankScaler()\n",
    "    data_all[cols_numeric] = scaler.fit_transform(data_all[cols_numeric])\n",
    "    \n",
    "else:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T08:07:41.358930Z",
     "iopub.status.busy": "2020-11-30T08:07:41.358076Z",
     "iopub.status.idle": "2020-11-30T08:07:43.419806Z",
     "shell.execute_reply": "2020-11-30T08:07:43.420450Z"
    },
    "papermill": {
     "duration": 2.105549,
     "end_time": "2020-11-30T08:07:43.420638",
     "exception": false,
     "start_time": "2020-11-30T08:07:41.315089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m PCA\n"
     ]
    }
   ],
   "source": [
    "# PCA\n",
    "if decompo == \"PCA\":\n",
    "    print(b_, \"PCA\")\n",
    "    GENES = [col for col in data_all.columns if col.startswith(\"g-\")]\n",
    "    CELLS = [col for col in data_all.columns if col.startswith(\"c-\")]\n",
    "    \n",
    "    pca_genes = PCA(n_components = ncompo_genes,\n",
    "                    random_state = seed).fit_transform(data_all[GENES])\n",
    "    pca_cells = PCA(n_components = ncompo_cells,\n",
    "                    random_state = seed).fit_transform(data_all[CELLS])\n",
    "    \n",
    "    pca_genes = pd.DataFrame(pca_genes, columns = [f\"pca_g-{i}\" for i in range(ncompo_genes)])\n",
    "    pca_cells = pd.DataFrame(pca_cells, columns = [f\"pca_c-{i}\" for i in range(ncompo_cells)])\n",
    "    data_all = pd.concat([data_all, pca_genes, pca_cells], axis = 1)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T08:07:43.496367Z",
     "iopub.status.busy": "2020-11-30T08:07:43.495342Z",
     "iopub.status.idle": "2020-11-30T08:07:43.512716Z",
     "shell.execute_reply": "2020-11-30T08:07:43.513630Z"
    },
    "papermill": {
     "duration": 0.066047,
     "end_time": "2020-11-30T08:07:43.513836",
     "exception": false,
     "start_time": "2020-11-30T08:07:43.447789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for feat in [\"cp_time\", \"cp_dose\"]:\n",
    "        data_all[feat] = LabelEncoder().fit_transform(data_all[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T08:07:43.610677Z",
     "iopub.status.busy": "2020-11-30T08:07:43.609676Z",
     "iopub.status.idle": "2020-11-30T08:07:43.924469Z",
     "shell.execute_reply": "2020-11-30T08:07:43.925672Z"
    },
    "papermill": {
     "duration": 0.367507,
     "end_time": "2020-11-30T08:07:43.925871",
     "exception": false,
     "start_time": "2020-11-30T08:07:43.558364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m One-Hot\n"
     ]
    }
   ],
   "source": [
    "# Encoding\n",
    "if encoding == \"lb\":\n",
    "    print(b_, \"Label Encoding\")\n",
    "    for feat in [\"cp_time\", \"cp_dose\"]:\n",
    "        data_all[feat] = LabelEncoder().fit_transform(data_all[feat])\n",
    "elif encoding == \"dummy\":\n",
    "    print(b_, \"One-Hot\")\n",
    "    data_all = pd.get_dummies(data_all, columns = [\"cp_time\", \"cp_dose\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T08:07:44.022851Z",
     "iopub.status.busy": "2020-11-30T08:07:44.022086Z",
     "iopub.status.idle": "2020-11-30T08:07:48.766472Z",
     "shell.execute_reply": "2020-11-30T08:07:48.765626Z"
    },
    "papermill": {
     "duration": 4.797122,
     "end_time": "2020-11-30T08:07:48.766581",
     "exception": false,
     "start_time": "2020-11-30T08:07:43.969459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.06it/s]\n"
     ]
    }
   ],
   "source": [
    "GENES = [col for col in data_all.columns if col.startswith(\"g-\")]\n",
    "CELLS = [col for col in data_all.columns if col.startswith(\"c-\")]\n",
    "\n",
    "for stats in tqdm.tqdm([\"sum\", \"mean\", \"std\", \"kurt\", \"skew\"]):\n",
    "    data_all[\"g_\" + stats] = getattr(data_all[GENES], stats)(axis = 1)\n",
    "    data_all[\"c_\" + stats] = getattr(data_all[CELLS], stats)(axis = 1)    \n",
    "    data_all[\"gc_\" + stats] = getattr(data_all[GENES + CELLS], stats)(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T08:07:48.844306Z",
     "iopub.status.busy": "2020-11-30T08:07:48.843502Z",
     "iopub.status.idle": "2020-11-30T08:07:49.545144Z",
     "shell.execute_reply": "2020-11-30T08:07:49.546580Z"
    },
    "papermill": {
     "duration": 0.74972,
     "end_time": "2020-11-30T08:07:49.546791",
     "exception": false,
     "start_time": "2020-11-30T08:07:48.797071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#新训练过程，将每种药物在每个fold中平均分配\n",
    "\n",
    "# LOAD FILES\n",
    "#scored = pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv')\n",
    "drug = pd.read_csv('/kaggle/input/lish-moa/train_drug.csv')\n",
    "targets_inhibitor = targets.columns[1:]\n",
    "targets = targets.merge(drug, on='sig_id', how='left') \n",
    "\n",
    "# LOCATE DRUGS\n",
    "vc = targets.drug_id.value_counts()\n",
    "vc1 = vc.loc[vc<=18].index.sort_values()\n",
    "vc2 = vc.loc[vc>18].index.sort_values()\n",
    "\n",
    "# STRATIFY DRUGS 18X OR LESS\n",
    "dct1 = {}; dct2 = {}\n",
    "skf = MultilabelStratifiedKFold(n_splits=NB_SPLITS, shuffle=True, \n",
    "          random_state=seed)\n",
    "tmp = targets.groupby('drug_id')[targets_inhibitor].mean().loc[vc1]\n",
    "for fold,(idxT,idxV) in enumerate( skf.split(tmp,tmp[targets_inhibitor])):\n",
    "    dd = {k:fold for k in tmp.index[idxV].values}\n",
    "    dct1.update(dd)\n",
    "\n",
    "# STRATIFY DRUGS MORE THAN 18X\n",
    "skf = MultilabelStratifiedKFold(n_splits=NB_SPLITS, shuffle=True, \n",
    "          random_state=seed)\n",
    "tmp = targets.loc[targets.drug_id.isin(vc2)].reset_index(drop=True)\n",
    "for fold,(idxT,idxV) in enumerate( skf.split(tmp,tmp[targets_inhibitor])):\n",
    "    dd = {k:fold for k in tmp.sig_id[idxV].values}\n",
    "    dct2.update(dd)\n",
    "\n",
    "# ASSIGN FOLDS\n",
    "targets['fold'] = targets.drug_id.map(dct1)\n",
    "targets.loc[targets.fold.isna(),'fold'] =\\\n",
    "    targets.loc[targets.fold.isna(),'sig_id'].map(dct2)\n",
    "targets.fold = targets.fold.astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T08:07:49.687450Z",
     "iopub.status.busy": "2020-11-30T08:07:49.686338Z",
     "iopub.status.idle": "2020-11-30T08:07:50.500668Z",
     "shell.execute_reply": "2020-11-30T08:07:50.499599Z"
    },
    "papermill": {
     "duration": 0.877598,
     "end_time": "2020-11-30T08:07:50.500805",
     "exception": false,
     "start_time": "2020-11-30T08:07:49.623207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"data_all.pickle\", \"wb\") as f:\n",
    "    pickle.dump(data_all, f)\n",
    "with open(\"data_all.pickle\", \"rb\") as f:\n",
    "    data_all = pickle.load(f)\n",
    "# train_df and test_df\n",
    "features_to_drop = [\"sig_id\", \"cp_type\"]\n",
    "data_all.drop(features_to_drop, axis = 1, inplace = True)\n",
    "try:\n",
    "    targets.drop([\"sig_id\",'drug_id'], axis = 1, inplace = True)\n",
    "except:\n",
    "    pass\n",
    "train_df = data_all[: train.shape[0]]\n",
    "train_df.reset_index(drop = True, inplace = True)\n",
    "# The following line it's a bad practice in my opinion, targets on train set\n",
    "#train_df = pd.concat([train_df, targets], axis = 1)\n",
    "test_df = data_all[train_df.shape[0]: ]\n",
    "test_df.reset_index(drop = True, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T08:07:50.573446Z",
     "iopub.status.busy": "2020-11-30T08:07:50.571755Z",
     "iopub.status.idle": "2020-11-30T08:07:50.581176Z",
     "shell.execute_reply": "2020-11-30T08:07:50.580645Z"
    },
    "papermill": {
     "duration": 0.047767,
     "end_time": "2020-11-30T08:07:50.581276",
     "exception": false,
     "start_time": "2020-11-30T08:07:50.533509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mtrain_df.shape: \u001b[31m(21948, 947)\n",
      "\u001b[34mtest_df.shape: \u001b[31m(3624, 947)\n",
      "\u001b[34mX_test.shape: \u001b[31m(3624, 947)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{b_}train_df.shape: {r_}{train_df.shape}\")\n",
    "print(f\"{b_}test_df.shape: {r_}{test_df.shape}\")\n",
    "\n",
    "X_test = test_df.values\n",
    "print(f\"{b_}X_test.shape: {r_}{X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T08:07:50.648312Z",
     "iopub.status.busy": "2020-11-30T08:07:50.647664Z",
     "iopub.status.idle": "2020-11-30T08:07:50.651252Z",
     "shell.execute_reply": "2020-11-30T08:07:50.651700Z"
    },
    "papermill": {
     "duration": 0.04052,
     "end_time": "2020-11-30T08:07:50.651815",
     "exception": false,
     "start_time": "2020-11-30T08:07:50.611295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_EPOCH = 200\n",
    "# n_d and n_a are different from the original work, 32 instead of 24\n",
    "# This is the first change in the code from the original\n",
    "tabnet_params = dict(\n",
    "    n_d = 24,\n",
    "    n_a = 40,\n",
    "    n_steps = 1,\n",
    "    gamma = 1.3,\n",
    "    lambda_sparse = 0,\n",
    "    optimizer_fn = optim.Adam,\n",
    "    #optimizer_fn = optim.SGD,\n",
    "    optimizer_params = dict(lr = 2e-2, weight_decay = 1e-5),\n",
    "    #optimizer_params = dict(lr = 6e-2,momentum=0.9,\n",
    "    #                  weight_decay=0),\n",
    "    \n",
    "    mask_type = \"entmax\",\n",
    "    scheduler_params = dict(\n",
    "        mode = \"min\", patience = 12, min_lr = 1e-5, factor = 0.9),\n",
    "    scheduler_fn = ReduceLROnPlateau,\n",
    "    seed = seed,\n",
    "    verbose = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T08:07:50.722023Z",
     "iopub.status.busy": "2020-11-30T08:07:50.720140Z",
     "iopub.status.idle": "2020-11-30T08:07:50.722709Z",
     "shell.execute_reply": "2020-11-30T08:07:50.723185Z"
    },
    "papermill": {
     "duration": 0.041047,
     "end_time": "2020-11-30T08:07:50.723295",
     "exception": false,
     "start_time": "2020-11-30T08:07:50.682248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class LogitsLogLoss(Metric):\n",
    "    \"\"\"\n",
    "    LogLoss with sigmoid applied\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self._name = \"logits_ll\"\n",
    "        self._maximize = False\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Compute LogLoss of predictions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_true: np.ndarray\n",
    "            Target matrix or vector\n",
    "        y_score: np.ndarray\n",
    "            Score matrix or vector\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            float\n",
    "            LogLoss of predictions vs targets.\n",
    "        \"\"\"\n",
    "        logits = 1 / (1 + np.exp(-y_pred))\n",
    "        aux = (1 - y_true) * np.log(1 - logits + 1e-15) + y_true * np.log(logits + 1e-15)\n",
    "        return np.mean(-aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T08:07:50.795186Z",
     "iopub.status.busy": "2020-11-30T08:07:50.794513Z",
     "iopub.status.idle": "2020-11-30T08:07:50.797356Z",
     "shell.execute_reply": "2020-11-30T08:07:50.797780Z"
    },
    "papermill": {
     "duration": 0.044426,
     "end_time": "2020-11-30T08:07:50.797900",
     "exception": false,
     "start_time": "2020-11-30T08:07:50.753474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LabelSmoothLoss(nn.Module):\n",
    "    def __init__(self, smoothing=0.0,class_num=2):\n",
    "        super(LabelSmoothLoss, self).__init__()\n",
    "        assert 0 <= smoothing < 1\n",
    "        self.smoothing = smoothing\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.class_num = class_num\n",
    "        \n",
    "    def smooth_binary(self,input):\n",
    "        one_confidence = torch.ones_like(input)*self.confidence\n",
    "        one_smoothing = torch.ones_like(input)*self.smoothing/self.class_num\n",
    "        if torch.cuda.is_available():\n",
    "            one_confidence = one_confidence.cuda()\n",
    "            one_smoothing = one_smoothing.cuda()\n",
    "        \n",
    "        m = torch.where(input >= 0.5, one_confidence, input)\n",
    "        m = torch.where(input <= 0.5, one_smoothing, m)\n",
    "        return m\n",
    "    \n",
    "    def forward(self, input, target):\n",
    "        target = self.smooth_binary(target)\n",
    "        return F.binary_cross_entropy_with_logits(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T08:07:50.863701Z",
     "iopub.status.busy": "2020-11-30T08:07:50.863082Z",
     "iopub.status.idle": "2020-11-30T08:07:50.867303Z",
     "shell.execute_reply": "2020-11-30T08:07:50.866822Z"
    },
    "papermill": {
     "duration": 0.038554,
     "end_time": "2020-11-30T08:07:50.867397",
     "exception": false,
     "start_time": "2020-11-30T08:07:50.828843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_with_label_smooth = LabelSmoothLoss(0.001,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T08:07:50.949700Z",
     "iopub.status.busy": "2020-11-30T08:07:50.948290Z",
     "iopub.status.idle": "2020-11-30T08:36:17.521951Z",
     "shell.execute_reply": "2020-11-30T08:36:17.520786Z"
    },
    "papermill": {
     "duration": 1706.623967,
     "end_time": "2020-11-30T08:36:17.522081",
     "exception": false,
     "start_time": "2020-11-30T08:07:50.898114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m FOLDS:  \u001b[31m 1\n",
      "\u001b[32m ************************************************************ \u001b[36m\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.22326 | val_logits_ll: 0.02534 |  0:00:02s\n",
      "epoch 10 | loss: 0.02115 | val_logits_ll: 0.01909 |  0:00:22s\n",
      "epoch 20 | loss: 0.02068 | val_logits_ll: 0.01804 |  0:00:42s\n",
      "epoch 30 | loss: 0.02044 | val_logits_ll: 0.01857 |  0:01:03s\n",
      "epoch 40 | loss: 0.02022 | val_logits_ll: 0.01749 |  0:01:23s\n",
      "epoch 50 | loss: 0.02032 | val_logits_ll: 0.0175  |  0:01:41s\n",
      "epoch 60 | loss: 0.02018 | val_logits_ll: 0.0176  |  0:02:01s\n",
      "epoch 70 | loss: 0.02003 | val_logits_ll: 0.01756 |  0:02:20s\n",
      "epoch 80 | loss: 0.0199  | val_logits_ll: 0.01757 |  0:02:38s\n",
      "epoch 90 | loss: 0.01993 | val_logits_ll: 0.01735 |  0:02:58s\n",
      "epoch 100| loss: 0.01972 | val_logits_ll: 0.0175  |  0:03:17s\n",
      "epoch 110| loss: 0.01974 | val_logits_ll: 0.01779 |  0:03:35s\n",
      "epoch 120| loss: 0.01954 | val_logits_ll: 0.01735 |  0:03:55s\n",
      "epoch 130| loss: 0.01939 | val_logits_ll: 0.01747 |  0:04:14s\n",
      "epoch 140| loss: 0.01938 | val_logits_ll: 0.01741 |  0:04:32s\n",
      "epoch 150| loss: 0.01929 | val_logits_ll: 0.01745 |  0:04:52s\n",
      "\n",
      "Early stopping occured at epoch 159 with best_epoch = 129 and best_val_logits_ll = 0.01721\n",
      "Best weights from best epoch are automatically used!\n",
      "\u001b[33m ------------------------------------------------------------\n",
      "\u001b[34m FOLDS:  \u001b[31m 2\n",
      "\u001b[32m ************************************************************ \u001b[36m\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.22541 | val_logits_ll: 0.02731 |  0:00:01s\n",
      "epoch 10 | loss: 0.02108 | val_logits_ll: 0.02025 |  0:00:21s\n",
      "epoch 20 | loss: 0.02052 | val_logits_ll: 0.01874 |  0:00:41s\n",
      "epoch 30 | loss: 0.02037 | val_logits_ll: 0.01826 |  0:01:01s\n",
      "epoch 40 | loss: 0.02016 | val_logits_ll: 0.01821 |  0:01:19s\n",
      "epoch 50 | loss: 0.02    | val_logits_ll: 0.01818 |  0:01:39s\n",
      "epoch 60 | loss: 0.01999 | val_logits_ll: 0.01818 |  0:01:59s\n",
      "epoch 70 | loss: 0.01993 | val_logits_ll: 0.01821 |  0:02:19s\n",
      "epoch 80 | loss: 0.01972 | val_logits_ll: 0.01826 |  0:02:38s\n",
      "\n",
      "Early stopping occured at epoch 82 with best_epoch = 52 and best_val_logits_ll = 0.01789\n",
      "Best weights from best epoch are automatically used!\n",
      "\u001b[33m ------------------------------------------------------------\n",
      "\u001b[34m FOLDS:  \u001b[31m 3\n",
      "\u001b[32m ************************************************************ \u001b[36m\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.22662 | val_logits_ll: 0.02696 |  0:00:01s\n",
      "epoch 10 | loss: 0.02109 | val_logits_ll: 0.0191  |  0:00:20s\n",
      "epoch 20 | loss: 0.02061 | val_logits_ll: 0.02016 |  0:00:39s\n",
      "epoch 30 | loss: 0.02035 | val_logits_ll: 0.01782 |  0:00:59s\n",
      "epoch 40 | loss: 0.0202  | val_logits_ll: 0.01781 |  0:01:19s\n",
      "epoch 50 | loss: 0.02013 | val_logits_ll: 0.01789 |  0:01:40s\n",
      "epoch 60 | loss: 0.01998 | val_logits_ll: 0.01758 |  0:02:00s\n",
      "epoch 70 | loss: 0.01988 | val_logits_ll: 0.01768 |  0:02:19s\n",
      "epoch 80 | loss: 0.01991 | val_logits_ll: 0.01774 |  0:02:38s\n",
      "epoch 90 | loss: 0.01976 | val_logits_ll: 0.01767 |  0:02:57s\n",
      "\n",
      "Early stopping occured at epoch 92 with best_epoch = 62 and best_val_logits_ll = 0.01756\n",
      "Best weights from best epoch are automatically used!\n",
      "\u001b[33m ------------------------------------------------------------\n",
      "\u001b[34m FOLDS:  \u001b[31m 4\n",
      "\u001b[32m ************************************************************ \u001b[36m\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.22352 | val_logits_ll: 0.02636 |  0:00:01s\n",
      "epoch 10 | loss: 0.02115 | val_logits_ll: 0.02141 |  0:00:19s\n",
      "epoch 20 | loss: 0.02061 | val_logits_ll: 0.01823 |  0:00:38s\n",
      "epoch 30 | loss: 0.02029 | val_logits_ll: 0.01803 |  0:00:57s\n",
      "epoch 40 | loss: 0.02024 | val_logits_ll: 0.0175  |  0:01:16s\n",
      "epoch 50 | loss: 0.02006 | val_logits_ll: 0.01754 |  0:01:34s\n",
      "epoch 60 | loss: 0.02001 | val_logits_ll: 0.01749 |  0:01:53s\n",
      "epoch 70 | loss: 0.01989 | val_logits_ll: 0.01758 |  0:02:13s\n",
      "epoch 80 | loss: 0.01977 | val_logits_ll: 0.01743 |  0:02:31s\n",
      "epoch 90 | loss: 0.0197  | val_logits_ll: 0.01752 |  0:02:50s\n",
      "epoch 100| loss: 0.01952 | val_logits_ll: 0.01764 |  0:03:10s\n",
      "epoch 110| loss: 0.01948 | val_logits_ll: 0.0173  |  0:03:29s\n",
      "epoch 120| loss: 0.01951 | val_logits_ll: 0.01753 |  0:03:50s\n",
      "epoch 130| loss: 0.01941 | val_logits_ll: 0.01749 |  0:04:10s\n",
      "epoch 140| loss: 0.01935 | val_logits_ll: 0.0174  |  0:04:28s\n",
      "\n",
      "Early stopping occured at epoch 143 with best_epoch = 113 and best_val_logits_ll = 0.01726\n",
      "Best weights from best epoch are automatically used!\n",
      "\u001b[33m ------------------------------------------------------------\n",
      "\u001b[34m FOLDS:  \u001b[31m 5\n",
      "\u001b[32m ************************************************************ \u001b[36m\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.22526 | val_logits_ll: 0.02561 |  0:00:01s\n",
      "epoch 10 | loss: 0.02149 | val_logits_ll: 0.02052 |  0:00:21s\n",
      "epoch 20 | loss: 0.0206  | val_logits_ll: 0.01815 |  0:00:40s\n",
      "epoch 30 | loss: 0.02038 | val_logits_ll: 0.01783 |  0:00:59s\n",
      "epoch 40 | loss: 0.02028 | val_logits_ll: 0.0178  |  0:01:20s\n",
      "epoch 50 | loss: 0.02013 | val_logits_ll: 0.01775 |  0:01:38s\n",
      "epoch 60 | loss: 0.02004 | val_logits_ll: 0.01755 |  0:01:58s\n",
      "epoch 70 | loss: 0.02006 | val_logits_ll: 0.01757 |  0:02:18s\n",
      "epoch 80 | loss: 0.01993 | val_logits_ll: 0.01762 |  0:02:37s\n",
      "\n",
      "Early stopping occured at epoch 89 with best_epoch = 59 and best_val_logits_ll = 0.01735\n",
      "Best weights from best epoch are automatically used!\n",
      "\u001b[33m ------------------------------------------------------------\n",
      "\u001b[34m FOLDS:  \u001b[31m 6\n",
      "\u001b[32m ************************************************************ \u001b[36m\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.22334 | val_logits_ll: 0.02775 |  0:00:01s\n",
      "epoch 10 | loss: 0.02099 | val_logits_ll: 0.02159 |  0:00:21s\n",
      "epoch 20 | loss: 0.02045 | val_logits_ll: 0.01908 |  0:00:40s\n",
      "epoch 30 | loss: 0.02013 | val_logits_ll: 0.0188  |  0:00:59s\n",
      "epoch 40 | loss: 0.0201  | val_logits_ll: 0.01855 |  0:01:19s\n",
      "epoch 50 | loss: 0.02001 | val_logits_ll: 0.01867 |  0:01:38s\n",
      "epoch 60 | loss: 0.02009 | val_logits_ll: 0.01881 |  0:01:57s\n",
      "epoch 70 | loss: 0.01989 | val_logits_ll: 0.01857 |  0:02:16s\n",
      "epoch 80 | loss: 0.01972 | val_logits_ll: 0.01852 |  0:02:36s\n",
      "epoch 90 | loss: 0.01969 | val_logits_ll: 0.01851 |  0:02:55s\n",
      "epoch 100| loss: 0.01959 | val_logits_ll: 0.01886 |  0:03:14s\n",
      "epoch 110| loss: 0.01961 | val_logits_ll: 0.01846 |  0:03:34s\n",
      "epoch 120| loss: 0.01952 | val_logits_ll: 0.01863 |  0:03:53s\n",
      "epoch 130| loss: 0.01966 | val_logits_ll: 0.01881 |  0:04:12s\n",
      "epoch 140| loss: 0.01947 | val_logits_ll: 0.01844 |  0:04:32s\n",
      "\n",
      "Early stopping occured at epoch 149 with best_epoch = 119 and best_val_logits_ll = 0.01828\n",
      "Best weights from best epoch are automatically used!\n",
      "\u001b[33m ------------------------------------------------------------\n",
      "\u001b[34m FOLDS:  \u001b[31m 7\n",
      "\u001b[32m ************************************************************ \u001b[36m\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.22243 | val_logits_ll: 0.02582 |  0:00:01s\n",
      "epoch 10 | loss: 0.02128 | val_logits_ll: 0.01926 |  0:00:20s\n",
      "epoch 20 | loss: 0.02063 | val_logits_ll: 0.01807 |  0:00:40s\n",
      "epoch 30 | loss: 0.02047 | val_logits_ll: 0.01778 |  0:00:59s\n",
      "epoch 40 | loss: 0.02042 | val_logits_ll: 0.01797 |  0:01:17s\n",
      "epoch 50 | loss: 0.02023 | val_logits_ll: 0.01753 |  0:01:37s\n",
      "epoch 60 | loss: 0.02019 | val_logits_ll: 0.01751 |  0:01:56s\n",
      "epoch 70 | loss: 0.02015 | val_logits_ll: 0.01745 |  0:02:15s\n",
      "epoch 80 | loss: 0.02004 | val_logits_ll: 0.01742 |  0:02:34s\n",
      "epoch 90 | loss: 0.02006 | val_logits_ll: 0.01785 |  0:02:53s\n",
      "epoch 100| loss: 0.01996 | val_logits_ll: 0.01774 |  0:03:12s\n",
      "epoch 110| loss: 0.01999 | val_logits_ll: 0.01754 |  0:03:31s\n",
      "epoch 120| loss: 0.01974 | val_logits_ll: 0.01748 |  0:03:50s\n",
      "epoch 130| loss: 0.01975 | val_logits_ll: 0.01756 |  0:04:09s\n",
      "epoch 140| loss: 0.01974 | val_logits_ll: 0.01744 |  0:04:28s\n",
      "epoch 150| loss: 0.01963 | val_logits_ll: 0.01751 |  0:04:48s\n",
      "\n",
      "Early stopping occured at epoch 157 with best_epoch = 127 and best_val_logits_ll = 0.01726\n",
      "Best weights from best epoch are automatically used!\n",
      "\u001b[33m ------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "scores_auc_all = []\n",
    "test_cv_preds = []\n",
    "\n",
    "oof_preds = []\n",
    "oof_targets = []\n",
    "scores = []\n",
    "scores_auc = []\n",
    "\n",
    "for fold_num in range(NB_SPLITS):\n",
    "    print(b_,\"FOLDS: \", r_, fold_num + 1)\n",
    "    print(g_, '*' * 60, c_)\n",
    "    test_fold = fold_num\n",
    "    train_fold = [x for x in range(NB_SPLITS) if x!=fold_num]\n",
    "    val_idx = targets['fold']==fold_num\n",
    "    train_idx = targets['fold']!=fold_num\n",
    "    \n",
    "    X_train, y_train = train_df.values[train_idx, :], targets.values[train_idx, :-1]\n",
    "    X_val, y_val = train_df.values[val_idx, :], targets.values[val_idx, :-1]\n",
    "    ### Model ###\n",
    "    model = TabNetRegressor(**tabnet_params)\n",
    "        \n",
    "    ### Fit ###\n",
    "    # Another change to the original code\n",
    "    # virtual_batch_size of 32 instead of 128\n",
    "    model.fit(\n",
    "        X_train = X_train,\n",
    "        y_train = y_train,\n",
    "        eval_set = [(X_val, y_val)],\n",
    "        eval_name = [\"val\"],\n",
    "        eval_metric = [\"logits_ll\"],\n",
    "        max_epochs = MAX_EPOCH,\n",
    "        patience = 30,\n",
    "        batch_size = 512, \n",
    "        virtual_batch_size = 64,\n",
    "        num_workers = 1,\n",
    "        drop_last = False,\n",
    "        # To use binary cross entropy because this is not a regression problem\n",
    "        #loss_fn = F.binary_cross_entropy_with_logits\n",
    "        loss_fn = loss_with_label_smooth\n",
    "    )\n",
    "    print(y_, '-' * 60)\n",
    "    \n",
    "    ### Predict on validation ###\n",
    "    preds_val = model.predict(X_val)\n",
    "    # Apply sigmoid to the predictions\n",
    "    preds = 1 / (1 + np.exp(-preds_val))\n",
    "    score = np.min(model.history[\"val_logits_ll\"])\n",
    "    \n",
    "    ### Save OOF for CV ###\n",
    "    oof_preds.append(preds_val)\n",
    "    oof_targets.append(y_val)\n",
    "    scores.append(score)\n",
    "    \n",
    "    ### Predict on test ###\n",
    "    preds_test = model.predict(X_test)\n",
    "    test_cv_preds.append(1 / (1 + np.exp(-preds_test)))\n",
    "\n",
    "oof_preds_all = np.concatenate(oof_preds)\n",
    "oof_targets_all = np.concatenate(oof_targets)\n",
    "test_preds_all = np.stack(test_cv_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T08:36:17.674296Z",
     "iopub.status.busy": "2020-11-30T08:36:17.673313Z",
     "iopub.status.idle": "2020-11-30T08:36:17.689486Z",
     "shell.execute_reply": "2020-11-30T08:36:17.688475Z"
    },
    "papermill": {
     "duration": 0.09191,
     "end_time": "2020-11-30T08:36:17.689595",
     "exception": false,
     "start_time": "2020-11-30T08:36:17.597685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save('oof.npy', oof_preds_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T08:36:17.835839Z",
     "iopub.status.busy": "2020-11-30T08:36:17.834985Z",
     "iopub.status.idle": "2020-11-30T08:36:17.839575Z",
     "shell.execute_reply": "2020-11-30T08:36:17.840194Z"
    },
    "papermill": {
     "duration": 0.080238,
     "end_time": "2020-11-30T08:36:17.840315",
     "exception": false,
     "start_time": "2020-11-30T08:36:17.760077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oof_preds_all.shape: (21948, 206)\n",
      "oof_targets_all.shape: (21948, 206)\n",
      "test_preds_all.shape: (7, 3624, 206)\n"
     ]
    }
   ],
   "source": [
    "print('oof_preds_all.shape:',oof_preds_all.shape)\n",
    "print('oof_targets_all.shape:',oof_targets_all.shape)\n",
    "print('test_preds_all.shape:',test_preds_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T08:36:17.986467Z",
     "iopub.status.busy": "2020-11-30T08:36:17.985762Z",
     "iopub.status.idle": "2020-11-30T08:36:19.176318Z",
     "shell.execute_reply": "2020-11-30T08:36:19.175466Z"
    },
    "papermill": {
     "duration": 1.26632,
     "end_time": "2020-11-30T08:36:19.176430",
     "exception": false,
     "start_time": "2020-11-30T08:36:17.910110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mOverall AUC: \u001b[31m0.6286943190510096\n",
      "\u001b[34mAverage CV: \u001b[31m0.017544881444833283\n"
     ]
    }
   ],
   "source": [
    "aucs = []\n",
    "for task_id in range(oof_preds_all.shape[1]):\n",
    "    aucs.append(roc_auc_score(y_true = oof_targets_all[:, task_id],\n",
    "                              y_score = oof_preds_all[:, task_id]\n",
    "                             ))\n",
    "print(f\"{b_}Overall AUC: {r_}{np.mean(aucs)}\")\n",
    "print(f\"{b_}Average CV: {r_}{np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T08:36:19.337187Z",
     "iopub.status.busy": "2020-11-30T08:36:19.336328Z",
     "iopub.status.idle": "2020-11-30T08:36:21.711894Z",
     "shell.execute_reply": "2020-11-30T08:36:21.712402Z"
    },
    "papermill": {
     "duration": 2.464473,
     "end_time": "2020-11-30T08:36:21.712537",
     "exception": false,
     "start_time": "2020-11-30T08:36:19.248064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34msubmission.shape: \u001b[31m(3982, 207)\n"
     ]
    }
   ],
   "source": [
    "#submission\n",
    "all_feat = [col for col in submission.columns if col not in [\"sig_id\"]]\n",
    "# To obtain the same lenght of test_preds_all and submission\n",
    "test = pd.read_csv(data_path + \"test_features.csv\")\n",
    "sig_id = test[test[\"cp_type\"] != \"ctl_vehicle\"].sig_id.reset_index(drop = True)\n",
    "tmp = pd.DataFrame(test_preds_all.mean(axis = 0), columns = all_feat)\n",
    "tmp[\"sig_id\"] = sig_id\n",
    "\n",
    "submission = pd.merge(test[[\"sig_id\"]], tmp, on = \"sig_id\", how = \"left\")\n",
    "submission.fillna(0, inplace = True)\n",
    "\n",
    "#submission[all_feat] = tmp.mean(axis = 0)\n",
    "\n",
    "# Set control to 0\n",
    "#submission.loc[test[\"cp_type\"] == 0, submission.columns[1:]] = 0\n",
    "submission.to_csv(\"submission.csv\", index = None)\n",
    "submission.head()\n",
    "print(f\"{b_}submission.shape: {r_}{submission.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 1789.547953,
   "end_time": "2020-11-30T08:36:22.811485",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-30T08:06:33.263532",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
